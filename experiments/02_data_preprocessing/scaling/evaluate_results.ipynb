{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#sys.path.append('../..')\n",
    "from scalers import scaler_identity\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "log_path = os.path.join(\"logs\",\"scalers_06\")\n",
    "part_res_path = os.path.join(log_path, \"partial_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dasc_GlobalMaxAbsScaler().pkl, dasc_GlobalMinMaxScaler().pkl, dasc_GlobalRobustScaler().pkl, dasc_GlobalStandardScaler().pkl, dasc_MaxAbsScaler().pkl, dasc_MinMaxScaler().pkl, dasc_RobustScaler().pkl, dasc_scaler_identity.pkl, dasc_StandardScaler().pkl, 4.4999924, 2.6640496, 1.3823587, 0.8937101, 7.322883, 2.1035473, 2.4571037, 741.0723, 1.7732216, \n",
      "6.7602353, 8.396039, 2.2024038, 2.0627444, 6.8354125, 2.896182, 1.681365, 689.5244, 1.1771886, \n",
      "5.2405887, 9.380862, 1.3228341, 1.9082696, 5.6046576, 2.5838728, 2.1641343, 974.69696, 1.6653384, \n",
      "6.0699887, 3.3474123, 1.7604774, 1.8830723, 6.5858874, 4.1027727, 1.2340094, 915.20667, 1.3902448, \n",
      "6.5574675, 3.1637297, 2.0383534, 1.3318852, 6.5334873, 3.9163065, 2.6538682, 718.91315, 1.8766227, \n",
      "6.3239856, 2.8341167, 1.8640803, 1.2108804, 7.1328244, 1.9987758, 1.524344, 690.6599, 3.196848, \n",
      "8.338198, 4.9960604, 2.1041477, 1.1245036, 5.4060974, 1.9459037, 1.3688649, 464.41498, 2.6356137, \n",
      "15.3368635, 5.3661976, 1.7484703, 1.3605425, 6.4585104, 3.6039355, 1.237625, 373.86966, 1.1462842, \n",
      "5.8993087, 9.198249, 1.6128386, 1.5629811, 8.268411, 2.1925669, 1.5466958, 943.32654, 1.1953236, \n",
      "7.526164, 4.415028, 1.9171282, 1.7319294, 9.257601, 2.22753, 2.338568, 744.7042, 2.744275, \n"
     ]
    }
   ],
   "source": [
    "for f in os.listdir(part_res_path):\n",
    "    print(f, end=\", \")\n",
    "for i in range(10):\n",
    "    for f in os.listdir(part_res_path):\n",
    "        #print(f)\n",
    "        partial_results = pd.read_pickle(os.path.join(part_res_path,f))\n",
    "        f_res = partial_results[\"results\"][\"kfolds\"]\n",
    "        #for res in f_res:\n",
    "        print(f_res[i][\"rmse_unscaled\"], end=\", \")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold_0</th>\n",
       "      <th>fold_1</th>\n",
       "      <th>fold_2</th>\n",
       "      <th>fold_3</th>\n",
       "      <th>fold_4</th>\n",
       "      <th>fold_5</th>\n",
       "      <th>fold_6</th>\n",
       "      <th>fold_7</th>\n",
       "      <th>fold_8</th>\n",
       "      <th>fold_9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scaler</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GlobalRobust</th>\n",
       "      <td>1.382359</td>\n",
       "      <td>2.202404</td>\n",
       "      <td>1.322834</td>\n",
       "      <td>1.760477</td>\n",
       "      <td>2.038353</td>\n",
       "      <td>1.864080</td>\n",
       "      <td>2.104148</td>\n",
       "      <td>1.748470</td>\n",
       "      <td>1.612839</td>\n",
       "      <td>1.917128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GlobalStandard</th>\n",
       "      <td>0.893710</td>\n",
       "      <td>2.062744</td>\n",
       "      <td>1.908270</td>\n",
       "      <td>1.883072</td>\n",
       "      <td>1.331885</td>\n",
       "      <td>1.210880</td>\n",
       "      <td>1.124504</td>\n",
       "      <td>1.360543</td>\n",
       "      <td>1.562981</td>\n",
       "      <td>1.731929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Robust</th>\n",
       "      <td>2.457104</td>\n",
       "      <td>1.681365</td>\n",
       "      <td>2.164134</td>\n",
       "      <td>1.234009</td>\n",
       "      <td>2.653868</td>\n",
       "      <td>1.524344</td>\n",
       "      <td>1.368865</td>\n",
       "      <td>1.237625</td>\n",
       "      <td>1.546696</td>\n",
       "      <td>2.338568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scaler_identity</th>\n",
       "      <td>741.072327</td>\n",
       "      <td>689.524414</td>\n",
       "      <td>974.696960</td>\n",
       "      <td>915.206665</td>\n",
       "      <td>718.913147</td>\n",
       "      <td>690.659912</td>\n",
       "      <td>464.414978</td>\n",
       "      <td>373.869659</td>\n",
       "      <td>943.326538</td>\n",
       "      <td>744.704224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Standard</th>\n",
       "      <td>1.773222</td>\n",
       "      <td>1.177189</td>\n",
       "      <td>1.665338</td>\n",
       "      <td>1.390245</td>\n",
       "      <td>1.876623</td>\n",
       "      <td>3.196848</td>\n",
       "      <td>2.635614</td>\n",
       "      <td>1.146284</td>\n",
       "      <td>1.195324</td>\n",
       "      <td>2.744275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     fold_0      fold_1      fold_2      fold_3      fold_4  \\\n",
       "scaler                                                                        \n",
       "GlobalRobust       1.382359    2.202404    1.322834    1.760477    2.038353   \n",
       "GlobalStandard     0.893710    2.062744    1.908270    1.883072    1.331885   \n",
       "Robust             2.457104    1.681365    2.164134    1.234009    2.653868   \n",
       "scaler_identity  741.072327  689.524414  974.696960  915.206665  718.913147   \n",
       "Standard           1.773222    1.177189    1.665338    1.390245    1.876623   \n",
       "\n",
       "                     fold_5      fold_6      fold_7      fold_8      fold_9  \n",
       "scaler                                                                       \n",
       "GlobalRobust       1.864080    2.104148    1.748470    1.612839    1.917128  \n",
       "GlobalStandard     1.210880    1.124504    1.360543    1.562981    1.731929  \n",
       "Robust             1.524344    1.368865    1.237625    1.546696    2.338568  \n",
       "scaler_identity  690.659912  464.414978  373.869659  943.326538  744.704224  \n",
       "Standard           3.196848    2.635614    1.146284    1.195324    2.744275  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw = None\n",
    "\n",
    "for f in os.listdir(part_res_path):\n",
    "    if \"MaxAbs\" in f or \"MinMax\" in f:\n",
    "        continue\n",
    "    partial_results = pd.read_pickle(os.path.join(part_res_path,f))\n",
    "    res_folds = partial_results[\"results\"][\"kfolds\"]\n",
    "    rmse_unscaled = [fold[\"rmse_unscaled\"] for fold in res_folds]\n",
    "    \n",
    "    temp_df = pd.DataFrame(rmse_unscaled).T  # Transpose the DataFrame to make it a row\n",
    "    temp_df.columns = [f\"fold_{i}\" for i in range(len(rmse_unscaled))]\n",
    "    scaler_name = f.replace(\".pkl\", \"\").replace(\"Scaler()\",\"\").replace(\"dasc_\",\"\")#.replace(\"Global\",\"\")\n",
    "    temp_df.insert(0, 'scaler', scaler_name)  # Insert the scaler name as the first column\n",
    "    \n",
    "    df_raw = pd.concat([df_raw, temp_df], ignore_index=True)\n",
    "df_raw = df_raw.set_index('scaler')\n",
    "df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import statsmodels.stats.multitest\n",
    "from critdd import Diagram\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "unscaled_samples = {}  # Initialize an empty dictionary\n",
    "\n",
    "for scaler, row in df_raw.iterrows():\n",
    "    unscaled_samples[scaler] = row.values.tolist() * 3\n",
    "\n",
    "#rmse_lists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 30)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FriedmanchisquareResult(statistic=64.08000000000004, pvalue=4.020173888637316e-13)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = list(unscaled_samples.values())\n",
    "print(np.array(samples).shape)\n",
    "friedman_result = stats.friedmanchisquare(*samples)\n",
    "friedman_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.86264515e-09 1.86264515e-09 1.86264515e-09 1.86264515e-09\n",
      " 7.29601830e-04 5.22633474e-02 6.05652314e-02 6.55438425e-01\n",
      " 7.00032922e-01 7.45654674e-01]\n",
      "1.862645149230957e-09 is st. significant\n",
      "1.862645149230957e-09 is st. significant\n",
      "1.862645149230957e-09 is st. significant\n",
      "1.862645149230957e-09 is st. significant\n",
      "0.0007296018302440643 is st. significant\n",
      "0.052263347432017326 is not st. significant\n",
      "0.01 is the threshold\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ True,  True,  True,  True,  True, False, False, False, False,\n",
       "        False]),\n",
       " array([1.86264515e-08, 1.86264515e-08, 1.86264515e-08, 1.86264515e-08,\n",
       "        4.37761098e-03, 2.61316737e-01, 2.61316737e-01, 1.00000000e+00,\n",
       "        1.00000000e+00, 1.00000000e+00]),\n",
       " 0.005116196891823743,\n",
       " 0.005)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combs = combinations(samples, 2)\n",
    "\n",
    "pvals = []\n",
    "for comb in combs:\n",
    "    pvals.append(stats.wilcoxon(comb[0], comb[1]).pvalue)\n",
    "\n",
    "pvals = np.array(pvals)\n",
    "pvals.sort()\n",
    "print(pvals)\n",
    "\n",
    "for i in range(len(pvals)):\n",
    "    if pvals[i] > 0.05/(len(pvals)-i):\n",
    "        print(f\"{pvals[i]} is not st. significant\")\n",
    "        print(f\"{0.05/(len(pvals)-i)} is the threshold\")\n",
    "        break\n",
    "    else:\n",
    "        print(f\"{pvals[i]} is st. significant\")\n",
    "\n",
    "statsmodels.stats.multitest.multipletests(pvals, method=\"holm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 5)\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "diag_df = pd.DataFrame(unscaled_samples)\n",
    "diag_np = diag_df.to_numpy()\n",
    "print(diag_np.shape)\n",
    "print(len(diag_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_df = pd.DataFrame(unscaled_samples)\n",
    "diag_np = diag_df.to_numpy()\n",
    "diagram = Diagram(\n",
    "    diag_df.to_numpy(),\n",
    "    treatment_names=diag_df.columns,\n",
    "    maximize_outcome = True,\n",
    ")\n",
    "\n",
    "#print(diagram.average_ranks)\n",
    "#diagram.get_groups(alpha=0.05, adjustment=\"holm\")\n",
    "diagram.to_file(\n",
    "    \"diagram.tex\",\n",
    "    alpha=0.05,\n",
    "    adjustment=\"holm\",\n",
    "    #reverse_x=True,\n",
    "    #axis_options = {\"title\", \"critdd\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSTM-crystal-growth-CmWzVl6A",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
