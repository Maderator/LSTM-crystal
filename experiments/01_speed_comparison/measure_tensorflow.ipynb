{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow 2.0 speed measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import timeit\n",
    "\n",
    "project_root = os.path.join(os.getcwd(), '..', '..')\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from python.data_processing import data_normalization, data_preprocessing\n",
    "from python.predictor.models.rnn_cells import LSTMPeepholeCell, ResidualLSTMCell\n",
    "\n",
    "training_shuffled = pickle.load(open('../../python/data/trainingShuffled.pkl', 'rb'))\n",
    "train_data = {}\n",
    "test_data = {}\n",
    "train_data[\"Inputs\"], test_data[\"Inputs\"], train_data[\"Outputs\"], test_data[\"Outputs\"] = train_test_split(training_shuffled[\"Inputs\"], training_shuffled[\"Outputs\"], test_size=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(450, 100, 2)\n",
      "(450, 100, 6)\n"
     ]
    }
   ],
   "source": [
    "print(training_shuffled[\"Inputs\"].shape)\n",
    "print(training_shuffled[\"Outputs\"].shape)\n",
    "train_data[\"Inputs\"].shape\n",
    "\n",
    "normalized_train_data, min, max = data_normalization.minmax_scale_data(train_data)\n",
    "normalized_test_data, _, _ = data_normalization.minmax_scale_data(test_data, min, max)\n",
    "norm_in, norm_out = normalized_train_data[\"Inputs\"], normalized_train_data[\"Outputs\"]\n",
    "preprocessed_train_data = data_preprocessing.lag_features(X=norm_in, y=norm_out, outputs_lag=3)\n",
    "preprocessed_test_data = data_preprocessing.lag_features(X=norm_in, y=norm_out, outputs_lag=3)\n",
    "\n",
    "input_shape = preprocessed_train_data[\"Inputs\"].shape[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Measure dependence of training time on networks depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_layers = [1,2,4]\n",
    "units = 20\n",
    "\n",
    "models = []\n",
    "for layers in max_layers:\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    for i in range(layers):\n",
    "        x = tf.keras.layers.LSTM(units, return_sequences=True)(x)\n",
    "    outputs = tf.keras.layers.Dense(6)(x)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"vanila_lstm_{}_layers\".format(layers))\n",
    "    models.append(model)\n",
    "\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    for i in range(layers):\n",
    "        x = tf.keras.layers.GRU(units, return_sequences=True)(x)\n",
    "    outputs = tf.keras.layers.Dense(6)(x)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"gru_{}_layers\".format(layers))\n",
    "    models.append(model)\n",
    "\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    for i in range(layers):\n",
    "        x = tf.keras.layers.RNN(LSTMPeepholeCell(units), return_sequences=True)(x)\n",
    "    outputs = tf.keras.layers.Dense(6)(x)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"peephole_lstm_{}_layers\".format(layers))\n",
    "    models.append(model)\n",
    "\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    for i in range(layers):\n",
    "        x = tf.keras.layers.RNN(ResidualLSTMCell(units), return_sequences=True)(x)\n",
    "    outputs = tf.keras.layers.Dense(6)(x)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"residual_lstm_{}_layers\".format(layers))\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vanila_lstm_1_layers\n",
      "gru_1_layers\n",
      "peephole_lstm_1_layers\n",
      "residual_lstm_1_layers\n",
      "vanila_lstm_2_layers\n",
      "gru_2_layers\n",
      "peephole_lstm_2_layers\n",
      "residual_lstm_2_layers\n",
      "vanila_lstm_4_layers\n",
      "gru_4_layers\n",
      "peephole_lstm_4_layers\n",
      "residual_lstm_4_layers\n"
     ]
    }
   ],
   "source": [
    "\n",
    "val_data = (preprocessed_test_data[\"Inputs\"], preprocessed_test_data[\"Outputs\"])\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "n_measurements = 4\n",
    "\n",
    "time_measurements = {}\n",
    "validation_rmses = {}\n",
    "for model in models:\n",
    "    print(model.name)\n",
    "    time_measurements[model.name] = []\n",
    "    validation_rmses[model.name] = []\n",
    "    for n in range(n_measurements):\n",
    "        model.compile(optimizer='adam',\n",
    "                    loss=tf.keras.losses.MeanSquaredError(),\n",
    "                    metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "        start = time.time()\n",
    "        result = model.fit(preprocessed_train_data[\"Inputs\"], preprocessed_train_data[\"Outputs\"], validation_data=val_data, epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "        end = time.time()\n",
    "        fit_time = end - start\n",
    "        time_measurements[model.name].append(fit_time)\n",
    "        validation_rmses[model.name].append(result.history[\"val_loss\"][-1])\n",
    "    time_measurements[model.name] = np.array(time_measurements[model.name])\n",
    "    validation_rmses[model.name] = np.array(validation_rmses[model.name])\n",
    "\n",
    "experiment = {}\n",
    "experiment[\"Name\"] = \"Tensorflow training time\"\n",
    "experiment[\"Description\"] = \"Measurements of training time for different LSTM cells using Tensorflow\"   \n",
    "experiment[\"Parameters\"] = {}\n",
    "experiment[\"Parameters\"][\"Epochs\"] = epochs\n",
    "experiment[\"Parameters\"][\"Batch size\"] = batch_size\n",
    "experiment[\"Parameters\"][\"Number of measurements\"] = n_measurements\n",
    "experiment[\"Parameters\"][\"Units\"] = units\n",
    "experiment[\"Time Measurements\"] = time_measurements\n",
    "experiment[\"Validation RMSE\"] = validation_rmses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the depth results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/tensorflow_depth_training_time.pkl\", \"wb\") as f:\n",
    "    pickle.dump(experiment, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Measure dependence of training time on networks width (units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = 1\n",
    "units_list = [10, 20, 50, 100, 200, 400]\n",
    "\n",
    "models = []\n",
    "for units in units_list:\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    x = tf.keras.layers.LSTM(units, return_sequences=True)(inputs)\n",
    "    outputs = tf.keras.layers.Dense(6)(x)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"vanila_lstm_{}_units\".format(units))\n",
    "    models.append(model)\n",
    "\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    x = tf.keras.layers.GRU(units, return_sequences=True)(inputs)\n",
    "    outputs = tf.keras.layers.Dense(6)(x)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"gru_{}_units\".format(units))\n",
    "    models.append(model)\n",
    "\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    x = tf.keras.layers.RNN(LSTMPeepholeCell(units), return_sequences=True)(inputs)\n",
    "    outputs = tf.keras.layers.Dense(6)(x)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"peephole_lstm_{}_units\".format(units))\n",
    "    models.append(model)\n",
    "\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    x = tf.keras.layers.RNN(ResidualLSTMCell(units), return_sequences=True)(inputs)\n",
    "    outputs = tf.keras.layers.Dense(6)(x)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"residual_lstm_{}_units\".format(units))\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vanila_lstm_10_units\n",
      "gru_10_units\n",
      "peephole_lstm_10_units\n",
      "residual_lstm_10_units\n",
      "vanila_lstm_20_units\n",
      "gru_20_units\n",
      "peephole_lstm_20_units\n",
      "residual_lstm_20_units\n",
      "vanila_lstm_50_units\n",
      "gru_50_units\n",
      "peephole_lstm_50_units\n",
      "residual_lstm_50_units\n",
      "vanila_lstm_100_units\n",
      "gru_100_units\n",
      "peephole_lstm_100_units\n",
      "residual_lstm_100_units\n",
      "vanila_lstm_200_units\n",
      "gru_200_units\n",
      "peephole_lstm_200_units\n",
      "residual_lstm_200_units\n",
      "vanila_lstm_400_units\n",
      "gru_400_units\n",
      "peephole_lstm_400_units\n",
      "residual_lstm_400_units\n"
     ]
    }
   ],
   "source": [
    "val_data = (preprocessed_test_data[\"Inputs\"], preprocessed_test_data[\"Outputs\"])\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "n_measurements = 4\n",
    "\n",
    "time_measurements = {}\n",
    "validation_rmses = {}\n",
    "for model in models:\n",
    "    print(model.name)\n",
    "    time_measurements[model.name] = []\n",
    "    validation_rmses[model.name] = []\n",
    "    for n in range(n_measurements):\n",
    "        model.compile(optimizer='adam',\n",
    "                    loss=tf.keras.losses.MeanSquaredError(),\n",
    "                    metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "        start = time.time()\n",
    "        result = model.fit(preprocessed_train_data[\"Inputs\"], preprocessed_train_data[\"Outputs\"], validation_data=val_data, epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "        end = time.time()\n",
    "        fit_time = end - start\n",
    "        time_measurements[model.name].append(fit_time)\n",
    "        validation_rmses[model.name].append(result.history[\"val_loss\"][-1])\n",
    "        # TODO: save last validation RMSE as the measured time\n",
    "    time_measurements[model.name] = np.array(time_measurements[model.name])\n",
    "    validation_rmses[model.name] = np.array(validation_rmses[model.name])\n",
    "\n",
    "experiment = {}\n",
    "experiment[\"Name\"] = \"Tensorflow training time\"\n",
    "experiment[\"Description\"] = \"Measurements of training time for different LSTM cells using Tensorflow\"   \n",
    "experiment[\"Parameters\"] = {}\n",
    "experiment[\"Parameters\"][\"Epochs\"] = epochs\n",
    "experiment[\"Parameters\"][\"Batch size\"] = batch_size\n",
    "experiment[\"Parameters\"][\"Number of measurements\"] = n_measurements\n",
    "experiment[\"Parameters\"][\"Units\"] = units\n",
    "experiment[\"Time Measurements\"] = time_measurements\n",
    "experiment[\"Validation RMSE\"] = validation_rmses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the width results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/tensorflow_width_training_time.pkl\", \"wb\") as f:\n",
    "    pickle.dump(experiment, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
