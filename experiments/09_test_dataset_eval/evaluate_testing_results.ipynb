{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\janma\\Programovani\\diplomova_prace\\LSTM-crystal-growth\\.venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:184: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from experiments_utils import get_experiments_samples, load_logs_pickle\n",
    "from critdd import Diagram\n",
    "import numpy as np\n",
    "\n",
    "# Load test results\n",
    "l1_path = r\"logs/multi_layer_dynamic_1l_300\"\n",
    "l10_dyn_payh = r\"logs/multi_layer_dynamic_10l\"\n",
    "static_path  = r\"logs/multi_layer_static\"\n",
    "\n",
    "l1_logs = load_logs_pickle(l1_path, pickle_filename=\"testing_results.pkl\")\n",
    "l10_dyn_logs = load_logs_pickle(l10_dyn_payh, pickle_filename=\"testing_results.pkl\")\n",
    "static_logs = load_logs_pickle(static_path, pickle_filename=\"testing_results.pkl\")\n",
    "static_logs_1l = load_logs_pickle(static_path, pickle_filename=\"testing_results_1l.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1 lrFixed\n"
     ]
    }
   ],
   "source": [
    "for log in static_logs_1l:\n",
    "    print(log[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_squared_error': {'scaled': <optimization.data_classes.MetricResults at 0x1ca25587ad0>,\n",
       "  'unscaled': <optimization.data_classes.MetricResults at 0x1ca2574eff0>},\n",
       " 'root_mean_squared_error': {'scaled': <optimization.data_classes.MetricResults at 0x1ca2574fb00>,\n",
       "  'unscaled': <optimization.data_classes.MetricResults at 0x1ca25794650>},\n",
       " 'mean_absolute_error': {'scaled': <optimization.data_classes.MetricResults at 0x1ca25795160>,\n",
       "  'unscaled': <optimization.data_classes.MetricResults at 0x1ca25795c70>}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1_logs[0][\"test_results\"][0].metrics_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_experiment_metrics_for_model_n(test_results, model_n: int = 0, metric_summarization=\"metric_per_sample\"):\n",
    "    unscaled_metrics = test_results[model_n].metric_values[\"root_mean_squared_error\"][\"unscaled\"]\n",
    "    metric_values = getattr(unscaled_metrics, metric_summarization)\n",
    "    return metric_values\n",
    "\n",
    "# need only static experiments from l1_logs and l10_dyn_logs (other were trained with same parameters as dynamic/static experiments and therefore are suboptimal -> were not explained in text)\n",
    "def get_experiment_samples(logs, fold_k, dynamic_lr_ok=True, static_lr_ok=True, scaled=False):\n",
    "    exp_samples = []\n",
    "    exp_labels = []\n",
    "    for log in logs:\n",
    "        has_dynamic_lr = \"training-additional_callbacks\" in log[\"training_results\"] and log[\"training_results\"][\"training-additional_callbacks\"]\n",
    "        if (has_dynamic_lr and not dynamic_lr_ok) or (not has_dynamic_lr and not static_lr_ok):\n",
    "            continue\n",
    "        exp_labels.append(log[\"label\"])\n",
    "        exp_samples.append(log[\"test_results\"][fold_k].metrics_values[\"root_mean_squared_error\"][\"scaled\" if scaled else \"unscaled\"].metric_per_sample)\n",
    "\n",
    "    return exp_samples, exp_labels\n",
    "\n",
    "model_k = 0 # test models trained on k-th fold of the training data\n",
    "number_of_models = 1 # number of models to average over, if 1 then use only model trained on first fold\n",
    "scaled = False\n",
    "\n",
    "l1_vars = {\"logs\": l1_logs, \"fold_k\": model_k, \"dynamic_lr_ok\": True, \"static_lr_ok\": False, \"scaled\": scaled}\n",
    "l10_dyn_vars = {\"logs\": l10_dyn_logs, \"fold_k\": model_k, \"dynamic_lr_ok\": True, \"static_lr_ok\": False, \"scaled\": scaled}\n",
    "static_vars = {\"logs\": static_logs, \"fold_k\": model_k, \"dynamic_lr_ok\": False, \"static_lr_ok\": True, \"scaled\": scaled}\n",
    "static_1l_vars = {\"logs\": static_logs_1l, \"fold_k\": model_k, \"dynamic_lr_ok\": False, \"static_lr_ok\": True, \"scaled\": scaled}\n",
    "vars_for_exps = [l1_vars, l10_dyn_vars, static_vars, static_1l_vars]\n",
    "\n",
    "all_exp_samples, all_exp_labels = [], []\n",
    "for vars in vars_for_exps:\n",
    "    for model_k in range(number_of_models):\n",
    "        vars[\"fold_k\"] = model_k\n",
    "        s, l = get_experiment_samples(**vars)\n",
    "        if model_k == 0:\n",
    "            model_samples = s\n",
    "        else:\n",
    "            model_samples = np.concatenate((model_samples, s), axis=1)\n",
    "    all_exp_samples.extend(model_samples)\n",
    "    all_exp_labels.extend(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_exp_samples[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "['l1 lrDynamic', 'l10 lrDynamic', 'l6 lrDynamic', 'l4 lrDynamic', 'l2 lrDynamic', 'l2 lrFixed', 'l4 lrFixed', 'l6 lrFixed', 'l10 lrFixed', 'l1 lrFixed']\n"
     ]
    }
   ],
   "source": [
    "print(len(all_exp_samples))\n",
    "print(all_exp_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is scaled:  False ... We use standardisation (sklearn StandardScaler) for features scaling\n",
      "l10 lrDynamic: mean RMSE: 0.35402, median RMSE: 0.36042, std: 0.07552\n",
      "l6 lrFixed: mean RMSE: 0.36204, median RMSE: 0.37019, std: 0.06047\n",
      "l10 lrFixed: mean RMSE: 0.36491, median RMSE: 0.38415, std: 0.09361\n",
      "l6 lrDynamic: mean RMSE: 0.38862, median RMSE: 0.39463, std: 0.07743\n",
      "l4 lrDynamic: mean RMSE: 0.43002, median RMSE: 0.40741, std: 0.08443\n",
      "l1 lrFixed: mean RMSE: 0.44926, median RMSE: 0.47081, std: 0.10754\n",
      "l4 lrFixed: mean RMSE: 0.45630, median RMSE: 0.43610, std: 0.07885\n",
      "l2 lrFixed: mean RMSE: 0.48277, median RMSE: 0.43424, std: 0.10027\n",
      "l2 lrDynamic: mean RMSE: 0.48691, median RMSE: 0.50039, std: 0.05285\n",
      "l1 lrDynamic: mean RMSE: 0.53380, median RMSE: 0.54210, std: 0.12083\n"
     ]
    }
   ],
   "source": [
    "mean_samples = []\n",
    "for label, samples in zip(all_exp_labels, all_exp_samples):\n",
    "    mean_samples.append((label, np.mean(samples), np.median(samples), np.std(samples)))\n",
    "mean_samples.sort(key=lambda x: x[1])\n",
    "print(\"Is scaled: \", scaled, \"... We use standardisation (sklearn StandardScaler) for features scaling\")\n",
    "for label, mean, median, std_dev in mean_samples:\n",
    "    print(f\"{label}: mean RMSE: {mean:.5f}, median RMSE: {median:.5f}, std: {std_dev:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['l1 lrDynamic', 'l10 lrDynamic', 'l6 lrDynamic', 'l4 lrDynamic', 'l2 lrDynamic', 'l2 lrFixed', 'l4 lrFixed', 'l6 lrFixed', 'l10 lrFixed', 'l1 lrFixed']\n"
     ]
    }
   ],
   "source": [
    "x=np.array(all_exp_samples)\n",
    "treatment_names = all_exp_labels\n",
    "print(treatment_names)\n",
    "x = x.T\n",
    "diagram = Diagram(x,\n",
    "    treatment_names=treatment_names,\n",
    "    maximize_outcome = False,\n",
    ")\n",
    "\n",
    "diagram.to_file(\n",
    "    \"critdd_test_results.tex\",\n",
    "    alpha=0.05,\n",
    "    adjustment=\"holm\",\n",
    "    reverse_x=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['l1 lrDynamic', 'l10 lrDynamic', 'l6 lrDynamic', 'l4 lrDynamic', 'l2 lrDynamic', 'l2 lrFixed', 'l4 lrFixed', 'l6 lrFixed', 'l10 lrFixed', 'l1 lrFixed']\n"
     ]
    }
   ],
   "source": [
    "samples_per_group = 5\n",
    "\n",
    "all_exp_samples_grouped = []\n",
    "for sample in all_exp_samples:\n",
    "    groups = [sample[i:i+samples_per_group] for i in range(0, len(sample), samples_per_group)]\n",
    "    means = [np.mean(group) for group in groups]\n",
    "    all_exp_samples_grouped.append(means)\n",
    "\n",
    "x=np.array(all_exp_samples_grouped)\n",
    "treatment_names = all_exp_labels\n",
    "print(treatment_names)\n",
    "x = x.T\n",
    "diagram = Diagram(x,\n",
    "    treatment_names=treatment_names,\n",
    "    maximize_outcome = False,\n",
    ")\n",
    "\n",
    "diagram.to_file(\n",
    "    \"critdd_test_results_grouped.tex\",\n",
    "    alpha=0.05,\n",
    "    adjustment=\"holm\",\n",
    "    reverse_x=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
